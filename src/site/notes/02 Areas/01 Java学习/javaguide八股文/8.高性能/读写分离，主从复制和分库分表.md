---
{"dg-publish":true,"permalink":"/02 Areas/01 Java学习/javaguide八股文/8.高性能/读写分离，主从复制和分库分表/"}
---

## 读写分离

### 什么是读写分离？

见名思意，根据读写分离的名字，我们就可以知道：**读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。** 这样的话，就能够小幅提升写性能，大幅提升读性能。

我简单画了一张图来帮助不太清楚读写分离的小伙伴理解。

![068984be05e783edb1424de8fc6eaf13_MD5.png](/img/user/04%20Archives/image/068984be05e783edb1424de8fc6eaf13_MD5.png)

一般情况下，我们都会选择一主多从，也就是一台主数据库负责写，其他的从数据库负责读。主库和从库之间会进行数据同步，以保证从库中数据的准确性。这样的架构实现起来比较简单，并且也符合系统的写少读多的特点。

### 读写分离会带来什么问题？如何解决？

读写分离对于提升数据库的并发非常有效，但同时也带来了**主从同步延迟**。由于数据在主库写入后需要一定时间同步到从库，这个时间差导致主库和从库之间存在数据不一致性的问题。

**解决方案：**

1. **强制将读请求路由到主库处理**
   - 通过将读请求强制路由到主库，确保获取的是最新数据。虽然会增加主库负担，但实现起来比较简单，使用的比较多。
   - 例如，使用工具如 `Sharding-JDBC` 的 `HintManager` 分片键值管理器，可以**强制使用主库**进行读取操作，将必须获取最新数据的读请求交给主库处理。

2. **延迟读取**
   - 在主从同步延迟的基础上，延迟一定时间再进行读取操作，以确保数据已同步到从库。适用于某些场景对实时性要求不高的情况。
   - 设计业务流程时，对于一些对数据比较敏感的场景，你可以在完成写请求之后，避免立即进行请求操作。比如你支付成功之后，跳转到一个支付成功的页面，当你点击返回之后才返回自己的账户。


另外，[《MySQL 实战 45 讲》](https://time.geekbang.org/column/intro/100020801?code=ieY8HeRSlDsFbuRtggbBQGxdTh-1jMASqEIeqzHAKrI%3D)这个专栏中的[《读写分离有哪些坑？》](https://time.geekbang.org/column/article/77636)这篇文章还介绍了很多其他比较实际的解决办法，感兴趣的小伙伴可以自行研究一下。

### 如何实现读写分离？
在实现读写分离时，无论选择哪种具体的实现方案，通常包含以下几个步骤：
1. 部署多台数据库，选择其中的一台作为主数据库，其他的一台或者多台作为从数据库。
2. 保证主数据库和从数据库之间的数据是实时同步的，这个过程也就是我们常说的**主从复制**。
3. 系统将写请求交给主数据库处理，读请求交给从数据库处理。
#### 两种常用的实现方式
##### 1. 代理方式
![1ddb8596454c2613934222b3c8f29219_MD5.png](/img/user/04%20Archives/image/1ddb8596454c2613934222b3c8f29219_MD5.png)

们可以在应用和数据中间加了一个代理层。应用程序所有的数据请求都交给代理层处理，代理层负责分离读写请求，将它们路由到对应的数据库中。
提供类似功能的中间件有 **MySQL Router**（官方）、**Atlas**（基于 MySQL Proxy）、**MaxScale**、**MyCat**。
##### 2. 组件方式（推荐）
- 我们可以通过引入第三方组件来协助实现读写分离。例如使用 `sharding-jdbc` ，直接引入 jar 包开箱即用，非常方便。也节省了很多运维的成本。
推荐查阅 [sharding-jdbc 官方文档](https://shardingsphere.apache.org/document/legacy/3.x/document/cn/manual/sharding-jdbc/usage/read-write-splitting/)，了解更多关于读写分离的操作。

### 主从复制原理是什么？ #三星

MySQL binlog(二进制日志文件) 主要记录了 MySQL 数据库中数据的所有变化(数据库执行的所有 DDL 和 DML 语句)。因此，我们可以根据主库的binlog，将主库的数据同步到从库中。

![b2bd118f46e1fab6ca927796aaf74835_MD5.png](/img/user/04%20Archives/image/b2bd118f46e1fab6ca927796aaf74835_MD5.png)
MySQL服务器之间的主从同步基于binlog日志机制，主库使用二进制日志来**记录数据库的所有变化**，从库通过读取和执行该日志文件来保持和主服务器的数据一致。

**主从复制的步骤：**
- 主库将所有的写操作记录到binlog日志中并生成一个binlog dump线程，将binlog日志传给从库的I/O线程。
- 从库连接主库，然后创建两个线程，一个I/O线程，一个SQL线程。
- 从库的I/O线程请求主库的binlog，并将得到的binlog日志写到relay log(中继日志) 文件中。
- 从库的 SQL 线程读取 relay log 同步数据本地（也就是再执行一遍 SQL ），来实现主从的操作一致，达到最终数据一致的目的。


🌕 简单总结一下：

MySQL 主从复制是依赖于 binlog 。另外，常见的一些同步 MySQL 数据到其他数据源的工具（比如 canal）的底层一般也是依赖 binlog 。

## 分库分表

读写分离主要应对的是数据库读并发，没有解决数据库存储问题。试想一下：**如果 MySQL 一张表的数据量过大怎么办?**
换言之，**我们该如何解决 MySQL 的存储压力呢？**
答案之一就是 **分库分表**。

### 什么是分库？

**分库** 就是将数据库中的数据分散到不同的数据库上，可以垂直分库，也可以水平分库。
**垂直分库** 就是把单一数据库按照业务进行划分，不同的业务使用不同的数据库，进而将一个数据库的压力分担到多个数据库。
举个例子：说你将数据库中的用户表、订单表和商品表分别单独拆分为用户数据库、订单数据库和商品数据库。
![Pasted image 20240329100337.png](/img/user/04%20Archives/image/Pasted%20image%2020240329100337.png)

**水平分库** 是把同一个表按一定规则拆分到不同的数据库中，每个库可以位于不同的服务器上，这样就实现了水平扩展，解决了单表的存储和性能瓶颈的问题。
举个例子：订单表数据量太大，你对订单表进行了水平切分（水平分表），然后将切分后的 2 张订单表分别放在两个不同的数据库。
![Pasted image 20240329100350.png](/img/user/04%20Archives/image/Pasted%20image%2020240329100350.png)

### 什么是分表？

**分表** 就是对单表的数据进行拆分，可以是垂直拆分，也可以是水平拆分。
**垂直分表** 是对数据表列的拆分，把一张列比较多的表拆分为多张表。
举个例子：我们可以将用户信息表中的一些列单独抽出来作为一个表。
**水平分表** 是对数据表行的拆分，把一张行比较多的表拆分为多张表，可以解决单一表数据量过大的问题。
举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。
水平拆分只能解决单表数据量大的问题，为了提升性能，我们通常会选择将拆分后的多张表放在不同的数据库中。也就是说，水平分表通常和水平分库同时出现。

![分表](/img/user/02 Areas/01 Java学习/javaguide八股文/8.高性能/images/read-and-write-separation-and-library-subtable/two-forms-of-sub-table.png)

### 什么情况下需要分库分表？

遇到下面几种场景可以考虑分库分表：

- 单表的数据达到千万级别以上，数据库读写速度比较缓慢。
- 数据库中的数据占用的空间越来越大，备份时间越来越长。
- 应用的并发量太大。

### 常见的分片算法有哪些？

分片算法主要解决了数据被水平分片之后，数据究竟该存放在哪个表的问题。

- **哈希分片**：求指定 key（比如 id） 的哈希，然后根据哈希值确定数据应被放置在哪个表中。哈希分片比较适合随机读写的场景，不太适合经常需要范围查询的场景。
- **范围分片**：按照特性的范围区间（比如时间区间、ID 区间）来分配数据，比如 将 `id` 为 `1~299999` 的记录分到第一个库， `300000~599999` 的分到第二个库。范围分片适合需要经常进行范围查找的场景，不太适合随机读写的场景（数据未被分散，容易出现热点数据的问题）。
- **地理位置分片**：很多 NewSQL 数据库都支持地理位置分片算法，也就是根据地理位置（如城市、地域）来分配数据。
- **融合算法**：灵活组合多种分片算法，比如将哈希分片和范围分片组合。
- ......

### 分库分表会带来什么问题呢？

引入分库分表之后，会给系统带来什么挑战呢？

- **join 操作**：同一个数据库中的表分布在了不同的数据库中，导致无法使用 join 操作。这样就导致我们需要手动进行数据的封装，比如你在一个数据库中查询到一个数据之后，再根据这个数据去另外一个数据库中找对应的数据。不过，很多大厂的资深 DBA 都是建议尽量不要使用 join 操作。因为 join 的效率低，并且会对分库分表造成影响。对于需要用到 join 操作的地方，可以采用多次查询业务层进行数据组装的方法。不过，这种方法需要考虑业务上多次查询的事务性的容忍度。
	- [[02 Areas/01 Java学习/javaguide八股文/3.数据库/mysql/Mysql重要知识点/常见的SQL优化手段#4 避免多表连接\|常见的SQL优化手段#4 避免多表连接]]
- **事务问题**：同一个数据库中的表分布在了不同的数据库中，如果单个操作涉及到多个数据库，那么数据库自带的事务就无法满足我们的要求了。这个时候，我们就需要引入分布式事务了。关于分布式事务常见解决方案总结，网站上也有对应的总结：<https://javaguide.cn/distributed-system/distributed-transaction.html> 。
- **分布式 ID**：分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键已经没办法满足生成的主键唯一了。我们如何为不同的数据节点生成全局唯一主键呢？这个时候，我们就需要为我们的系统引入分布式 ID 了。关于分布式 ID 的详细介绍&实现方案总结，网站上也有对应的总结：<https://javaguide.cn/distributed-system/distributed-id.html> 。
- **跨库聚合查询问题**：分库分表会导致常规聚合查询操作，如 group by，order by 等变得异常复杂。这是因为这些操作需要在多个分片上进行数据汇总和排序，而不是在单个数据库上进行。为了实现这些操作，需要编写复杂的业务代码，或者使用中间件来协调分片间的通信和数据传输。这样会增加开发和维护的成本，以及影响查询的性能和可扩展性。
- ......

另外，引入分库分表之后，一般需要 DBA 的参与，同时还需要更多的数据库服务器，这些都属于成本。

### 分库分表有没有什么比较推荐的方案？
我们可以使用 ShardingSphere 来进行分库分表。
ShardingSphere 是一款分布式的数据库生态系统， 可以将任意数据库转换为分布式数据库，并通过数据分片、弹性伸缩、加密等能力对原有数据库进行增强。
ShardingSphere 的功能很完善，除了支持读写分离和分库分表，还提供分布式事务、数据库治理、影子库、数据加密和脱敏等功能。

![13c331d1847b62b42e9cec28316f3298_MD5.png](/img/user/04%20Archives/image/13c331d1847b62b42e9cec28316f3298_MD5.png)

ShardingSphere 的优势如下（摘自 ShardingSphere 官方文档：<https://shardingsphere.apache.org/document/current/cn/overview/>）：

- 极致性能：驱动程序端历经长年打磨，效率接近原生 JDBC，性能极致。
- 生态兼容：代理端支持任何通过 MySQL/PostgreSQL 协议的应用访问，驱动程序端可对接任意实现 JDBC 规范的数据库。
- 业务零侵入：面对数据库替换场景，ShardingSphere 可满足业务无需改造，实现平滑业务迁移。
- 运维低成本：在保留原技术栈不变前提下，对 DBA 学习、管理成本低，交互友好。
- 安全稳定：基于成熟数据库底座之上提供增量能力，兼顾安全性及稳定性。
- 弹性扩展：具备计算、存储平滑在线扩展能力，可满足业务多变的需求。
- 开放生态：通过多层次（内核、功能、生态）插件化能力，为用户提供可定制满足自身特殊需求的独有系统。

另外，ShardingSphere 的生态体系完善，社区活跃，文档完善，更新和发布比较频繁。

艿艿之前写了一篇分库分表的实战文章，各位朋友可以看看：[《芋道 Spring Boot 分库分表入门》](https://mp.weixin.qq.com/s/A2MYOFT7SP-7kGOon8qJaw) 。


### 分库分表后，数据怎么迁移呢？

在分库分表后，数据迁移是一个关键的环节，需要采取合适的方案来确保数据的完整性和一致性。常用的数据迁移方案包括停机迁移和双写方案。

1. **停机迁移**：
   - 停机迁移是一个比较简单常用的方案。在系统使用量较少的时间段，如凌晨时段，可以暂停系统服务，然后编写迁移脚本，将老库的数据同步到新库中。
2. **双写方案**：
   - 对于不能停机的场景，可以考虑使用双写方案进行数据迁移。
   - 在双写方案中，在对老库进行更新操作时，也将这些操作同步写入新库。
   - 在迁移过程中，我们还需要编写脚本来比对**老库和新库的数据**，如果新库中没有老库中的某条数据，那就把这些数据插入到新库；如果新库有而老库没有，则视为冗余数据，需要在新库中删除。

3. **增量数据迁移**：
   - 借助数据库同步工具（如 Canal）进行增量数据迁移，可以实现较低的开发和维护成本。这种方案基于数据库的 binlog 实现，可以将老库的增量数据同步到新库中，保持数据的实时性和一致性。


## 总结

- 读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。 这样的话，就能够小幅提升写性能，大幅提升读性能。
- 读写分离基于主从复制，MySQL 主从复制是依赖于 binlog 。
- **分库** 就是将数据库中的数据分散到不同的数据库上。**分表** 就是对单表的数据进行拆分，可以是垂直拆分，也可以是水平拆分。
- 引入分库分表之后，需要系统解决事务、分布式 id、无法 join 操作问题。
- ShardingSphere 绝对可以说是当前分库分表的首选！ShardingSphere 的功能完善，除了支持读写分离和分库分表，还提供分布式事务、数据库治理等功能。另外，ShardingSphere 的生态体系完善，社区活跃，文档完善，更新和发布比较频繁。
